{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNuh4DtX8HBORfrOk2vXSm0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"UDnwlZZBdVoo","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAlmxqvZ35Ij","colab_type":"code","colab":{}},"source":["from os import listdir\n","from pickle import dump\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.models import Model\n","from keras.models import load_model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2dRK9BN35LR","colab_type":"code","colab":{}},"source":["def extract_features(directory):\n","  model = VGG16()\n","  model.layers.pop()\n","  model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n","  print(model.summary())\n","  features = dict()\n","  for name in listdir(directory):\n","    filename = directory + '/' + name\n","    image = load_img(filename, target_size=(224,224))\n","    image = img_to_array(image)\n","    image= image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","    image = preprocess_input(image)\n","    feature = model.predict(image, verbose = 0)\n","    image_id = name.split('.')[0]\n","    features[image_id] = feature\n","    print('>%s' % name)\n","  return features\n","directory = '/content/gdrive/My Drive/Colab Notebooks/Flickr8k/Flickr8k_Dataset/Flicker8k_Dataset'\n","features = extract_features(directory)\n","print('Extracted features: %d' % len(features))\n","dump(features, open('features.pkl', 'wb'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnKtt15q35OP","colab_type":"code","colab":{}},"source":["import string \n","def load_doc(filename):\n","  file = open(filename, 'r')\n","  text = file.read()\n","  file.close()\n","  return text\n","def load_descriptions(doc):\n","  mapping  = dict()\n","  for line in doc.split('\\n'):\n","    token = line.split()\n","    if len(line) < 2:\n","      continue\n","    image_id, image_desc = token[0], token[1:]\n","    image_id = image_id.split('.')[0]\n","    image_desc = ' '.join(image_desc)\n","    if image_id not in mapping:\n","      mapping[image_id]=list()\n","      mapping[image_id].append(image_desc)\n","  return mapping\n","def clean_descriptions(descriptions):\n","  table = str.maketrans('', '', string.punctuation)\n","  for key,desc_list in descriptions.items():\n","    for i in range (len(desc_list)):\n","      desc = desc_list[i]\n","      desc = desc.split()\n","      desc = [word.lower() for word in desc]\n","      desc = [w.translate(table) for w in desc]  \n","      desc = [word for word in desc if len(word)>1]\n","      desc = [word for word in desc if word.isalpha()]\n","      desc_list[i] =' '.join(desc)\n","\n","def to_vocabulary(descriptions):\n","  all_desc = set()\n","  for key in descriptions.keys():\n","    [all_desc.update(d.split()) for d in descriptions[key]]\n","  return all_desc      \n","\n","\n","def save_descriptions(descriptions,filename):\n","  lines = list()\n","  for key, desc_list in descriptions.items():\n","    for desc in desc_list:\n","      lines.append(key + ' ' + desc)\n","    data = '\\n'.join(lines)\n","    file = open(filename, 'w')\n","    file.write(data)\n","    file.close()\n","\n","filename = '/content/gdrive/My Drive/Colab Notebooks/Flickr8k/Flickr8k_text/Flickr8k.token.txt'\n","doc = load_doc(filename)\n","descriptions = load_descriptions(doc)\n","print('Loaded: %d ' % len(descriptions))\n","clean_descriptions(descriptions)\n","vocabulary = to_vocabulary(descriptions)\n","print('Vocabulary Size: %d' % len(vocabulary))\n","save_descriptions(descriptions, 'descriptions.txt')\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KU9QPw84gSC3","colab_type":"code","colab":{}},"source":["from pickle import load\n","def load_doc(filename):\n","  file = open(filename, 'r')\n","  text =file.read()\n","  file.close()\n","  return text\n","\n","def load_set(filename):\n","  doc = load_doc(filename)\n","  dataset = list()\n","  for line in doc.split('\\n'):\n","    if len(line) < 1:\n","      continue\n","    identifier = line.split('.')[0]\n","    dataset.append(identifier)\n","  return set(dataset)\n","\n","def load_clean_descriptions(filename, dataset):\n","  doc = load_doc(filename)\n","  descriptions = dict()\n","  for line in doc.split('\\n'):\n","    tokens = line.split()\n","    image_id,image_desc = tokens[0], tokens[1:]\n","    if image_id in dataset:\n","      if image_id not in descriptions:\n","        descriptions[image_id] = list()\n","      desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n","      descriptions[image_id].append(desc)\n","  return descriptions\n","\n","def load_photo_features(filename, dataset):\n","  all_features = load(open(filename, 'rb'))\n","  features = {k: all_features[k] for k in dataset}\n","  return features\n","\n","filename = '/content/gdrive/My Drive/Colab Notebooks/Flickr8k/Flickr8k_text/Flickr_8k.trainImages.txt'\n","train = load_set(filename)\n","print('Dataset: %d' % len(train))\n","train_descriptions = load_clean_descriptions('descriptions.txt', train)\n","print('Descriptions: train=%d' % len(train_descriptions))\n","train_features = load_photo_features('features.pkl', train)\n","print('Photos: train=%d' % len(train_features))\n","\n","train_descriptions\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JC8E-Dp9NzVk","colab_type":"code","colab":{}},"source":["from numpy import array\n","import tensorflow\n","from pickle import load\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","from keras.utils import plot_model\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Embedding\n","from keras.layers import Dropout\n","from keras.layers.merge import add\n","from keras.callbacks import ModelCheckpoint\n","\n","def load_doc(filenmae):\n","  file = open(filename, 'r')\n","  text = file.read()\n","  file.close()\n","  return text\n","\n","def load_set(filename):\n","  doc = load_doc(filename)\n","  dataset = list()\n","  for line in doc.split('\\n'):\n","    if len(line) < 1:\n","      continue\n","    identifier = line.split('.')[0]\n","    dataset.append(identifier)\n","  return set(dataset)\n","\n","def load_clean_descriptions(filename, dataset):\n","  doc = load_doc(filename)\n","  descriptions = dict()\n","  for line in doc.spli('\\n'):\n","    tokens = line.split()\n","    image_id,image_desc = tokens[0], tokens[1:]\n","    if image_id in dataset:\n","      if image_id not in descriptions:\n","        descriptions[image_id] = list()\n","      desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n","      descriptions[image_id].append(desc)\n","  return descriptions\n","\n","def load_photo_features(filename, dataset):\n","  all_features = load(open(filename, 'rb'))\n","  features = {k: all_features[k] for k in dataset}\n","  return features\n","\n","def to_lines(descriptions):\n","  all_desc = list()\n","  for key in descriptions.keys():\n","    [all_desc.append(d) for d in descriptions[key]]\n","  return all_desc\n","\n","def create_tokenizer(descriptions):\n","  lines = to_lines(descriptions)\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(lines)\n","  return tokenizer\n","\n","tokenizer = create_tokenizer(train_descriptions)\n","vocab_size = len(tokenizer.word_index) + 1\n","print('Vocabulary Size: %d' % vocab_size)\n","\n","def max_length(descriptions):\n","  \n","  lines = to_lines(descriptions)\n","  return max(len(d.split()) for d in lines)\n","\n","def create_sequences(tokenizer, max_length, desc_list, photo):\n","  X1, X2, y = list(), list(), list()\n","  for desc in desc_list:\n","    seq = tokenizer.texts_to_sequences([desc])[0]\n","    for i in range(1, len(seq)):\n","      in_seq, out_seq = seq[:i], seq[i]\n","      in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","      out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","      X1.append(photo)\n","      X2.append(in_seq)\n","      y.append(out.seq)\n","  return array(X1), array(X2), array(y)\n","\n","def define_model(vocab_size, max_length):\n","  inputs1 = Input(shape=(4096,))\n","  fe1 = Dropout(0.5)(inputs1)\n","  fe2 = Dense(256, activation='relu')(fe1)\n","\n","  inputs2 = Input(shape=(max_length,))\n","  se1 = Embedding(vocab_size, 256, mask_zero=true)(inputs2)\n","  se2 = Dropout(0.5)(se1)\n","  se3 = LSTM(256)(se2)\n","\n","  decoder1 = add([fe2, se3])\n","  decoder2 = Dense(256, activation='relu')(decoder1)\n","  outputs = Dense(256, activation='softmax')(decoder2)\n","\n","  model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","  model.compile(loss='categorical_crossentropy', optimizer='adam')\n","\n","  print(model.summary())\n","  return model\n","\n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLCgIE8UeKcK","colab_type":"code","colab":{}},"source":["def data_generator(descriptions, photos, tokenizer, max_length):\n","  while 1:\n","    for key, desc_list in descriptions.items():\n","      photo = photos[key][0]\n","      in_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo)\n","      yield [[in_img, in_seq],out_word]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RyjNDXP8e54h","colab_type":"code","colab":{}},"source":["filename='/content/gdrive/My Drive/Colab Notebooks/Flickr8k/Flickr8k_text/Flickr_8k.trainImages.txt'\n","train = load_set(filename)\n","print('Dataset: %d' % len(train))\n","train_descriptions = load_clean_descriptions('descriptions.txt', train)\n","print('Descriptions: train=%d' % len(train_descriptions))\n","train_features = load_photo_features('features.pkl', train)\n","print('photos: train=%d' % len(train_features))\n","tokenizer = create_tokenizer(train_descriptions)\n","dump(tokenizer, open('tokenizer.pkl', 'wb'))\n","vocab_size = len(tokenizer.word_index) + 1\n","print('vocabulary Size: %d' % vocab_size)\n","max_length = max_length(train_descriptions)\n","print('Description length: % d' % max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnvzDDJzhVmD","colab_type":"code","colab":{}},"source":["model = define_model(vocab_size, max_length)\n","epochs = 3\n","steps = len(train_descriptions)\n","for i in range(epochs):\n","  generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n","  model.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n","  model.save('model_' + str(i) + '.h5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZoiabMJVi13q","colab_type":"code","colab":{}},"source":["from numpy import argmax\n","from pickle import load\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import load_model\n","from nltk.translate.bleu_score import corpus_bleu\n","def load_doc(filename):\n","  file = open(filename, 'r')\n","  text = file.read()\n","  file.close()\n","  return text\n","\n","def load_set(filename):\n","  doc = load_doc(filename)\n","  dataset = list()\n","  for line in doc.split('\\n'):\n","    if len(line) < 1:\n","      continue\n","    identifier = line.split('.')[0]\n","    dataset.append(identifier)\n","  return set(dataset)\n","\n","\n","def load_clean_descriptions(filename, dataset):\n","  doc = load_doc(filename)\n","  descriptions = dict()\n","  for line in doc.spli('\\n'):\n","    tokens = line.split()\n","    image_id,image_desc = tokens[0], tokens[1:]\n","    if image_id in dataset:\n","      if image_id not in descriptions:\n","        descriptions[image_id] = list()\n","      desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n","      descriptions[image_id].append(desc)\n","  return descriptions\n","\n","def load_photo_features(filename, dataset):\n","  all_features = load(open(filename, 'rb'))\n","  features = {k: all_features[k] for k in dataset}\n","  return features\n","\n","def to_lines(descriptions):\n","  all_desc = list()\n","  for key in descriptions.keys():\n","    [all_desc.append(d) for d in descriptions[key]]\n","  return all_desc\n","\n","def create_tokenizer(descriptions):\n","  lines = to_lines(descriptions)\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(lines)\n","  return tokenizer\n","def max_length(descriptions):\n","  lines = to_lines(descriptions)\n","  return max(len(d.split()) for d in lines)\n","def word_for_id(integer, tokenizer):\n","  for word, index in tokenizer.word_index.items():\n","    if index == integer:\n","      return word\n","  return None\n","def generate_desc(model, tokenizer, photo, max_length):\n","  in_text = 'startseq'\n","  for i in range(max_length):\n","    sequence = tokenizer.texts_to_sequences([in_text])[0]\n","    sequence = pad_sequences([sequence], maxlen=max_length)\n","    yhat = model.predict([photo,sequence], verbose=0)\n","    yhat = argmax(yhat)\n","    word = word_for_id(yhat, tokenizer)\n","    if word is None:\n","      break;\n","    in_text += ' ' + word\n","    if word == 'endseq':\n","      break\n","  return_in_text\n","def evaluate_model(model, description, photos, tokenizer, max_length):\n","  actual, predicted = list(), list()\n","  for key, desc_list in descriptions.items():\n","    yhat = generate_desc(model, tokenizer, photos[key], max_length)\n","    references = [d.split() for d in desc_list]\n","    actual.append(references)\n","    predicted.append(yhat.split())\n","\n","  print('BLEU-1: %f' % corpus_bleu(actual,predicted, weights=(1.0, 0, 0, 0)))\n","  print('BLEU-2: %f' % corpus_bleu(actual,predicted, weights=(0.5, 0.5, 0, 0)))\n","  print('BLEU-3: %f' % corpus_bleu(actual,predicted, weights=(0.3, 0.3, 0.3, 0)))\n","  print('BLEU-4: %f' % corpus_bleu(actual,predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n","\n","  filename = '/content/gdrive/My Drive/Colab Notebooks/Flickr8k/Flickr8k_text/Flickr_8k.trainImages.txt'\n","  train = load_set(filename)\n","  print('Dataset: %d' % len(train))\n","  train_descriptions = load_clean_descriptions('descriptions.txt', train)\n","  print('Descriptions: train=%d' % len(train_descriptions))\n","\n","  tokenizer = create_tokenizer(train_description)\n","  vocab_size = len(tokenizer.word_index) + 1\n","  print('Vocabulary size: %d' % vocab_size)\n","  max_length = max_length(train_descriptions)\n","  print('Description length: %d' % max_length)\n","\n","  filename = '/content/gdrive/My Drive/Colab Notebooks/Flickr8k/Flickr8k_text/Flickr_8k.testImages.txt '\n","  test = load_set(filename)\n","  print('Dataset: %d' % len(test))\n","  test_descriptions = load_clean_descriptions('descriptions.txt', test)\n","  print('Descriptions: test=%d' % len(test_descriptions))\n","\n","  test_features = load_photo_features('features.pkl', test)\n","  print('Photos: test=%d' % len(test_features))\n","\n","  filename = 'model_2.h5'\n","  model = load_model(filename)\n","  evaluate_model(model, test_descriptions, test_features, tokenizer, max_length)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuAmtRoX63_3","colab_type":"code","colab":{}},"source":["def extract_features(filename):\n","  model = VGG16()\n","  model.layers.pop()\n","  model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n","  image = load_img(filename, target_size=(224,224))\n","  image = img_to_array(image)\n","  image= image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","  mage = preprocess_input(image)\n","  feature = model.predict(image, verbose = 0)\n","  return features \n","\n","tokenizer = load(open('tokenizer.pkl', 'rb'))\n","max_length = 34\n","model = load_model('model_2.h5')\n","photo = extract_features('/content/gdrive/My Drive/SAVE_20200813_204502.jpg')\n","description = generate_desc(model, tokenizer, photo, max_length)\n","print(description)\n","\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8J4ESBHq-D_q","colab_type":"code","colab":{}},"source":["query = description\n","stopwords = [startseq, endseq]\n","querywords = query.split()\n","resultwords = [word for word in querywordsif word.lower() not in stopwords]\n","result = ' '.join(resultwords)\n","print(result)"],"execution_count":null,"outputs":[]}]}